{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from loguru import logger\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, \n",
    "           level=\"INFO\",\n",
    "           format=\"{time:HH:mm:ss} | {level} | {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(csv_input, csv_types):\n",
    "\n",
    "        df_input = pd.read_csv(csv_input)\n",
    "        df_types = pd.read_csv(csv_types)\n",
    "        \n",
    "        G = nx.Graph() \n",
    "\n",
    "        # Add nodes with entity_type property\n",
    "        entities = set(df_input['entity_1']).union(set(df_input['entity_2']))\n",
    "        \n",
    "        for entity in entities:\n",
    "            entity_type = df_types.loc[df_types['entity_name'] == entity, 'entity_type'].values\n",
    "            assert len(entity_type) > 0, f\"Entity type not found for entity: {entity}\"\n",
    "            G.add_node(entity, entity_type = entity_type[0])\n",
    "                \n",
    "        # Add edges\n",
    "        for _, row in df_input.iterrows():\n",
    "            relationship_type = row['relationship']\n",
    "            assert len(entity_type) > 0, f\"Relationship type not found for entities: {row}\"\n",
    "            G.add_edge(row['entity_1'], row['entity_2'], relationship = relationship_type)\n",
    "        \n",
    "        return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions formatted\n",
    "\n",
    "accepts CSV file input from already processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rough_fit_functions(G, csv_input, csv_types):\n",
    "    \n",
    "    \"\"\"\n",
    "    Accepts three variables:\n",
    "    - An existing network graph G\n",
    "    - A csv file of relationship data\n",
    "    - A csv file of entity type data\n",
    "    \"\"\"\n",
    "    \n",
    "    def create_graph(csv_input, csv_types):\n",
    "\n",
    "        df_input = pd.read_csv(csv_input)\n",
    "        df_types = pd.read_csv(csv_types)\n",
    "        \n",
    "        G = nx.Graph() \n",
    "\n",
    "        # Add nodes with entity_type property\n",
    "        entities = set(df_input['entity_1']).union(set(df_input['entity_2']))\n",
    "        \n",
    "        for entity in entities:\n",
    "            entity_type = df_types.loc[df_types['entity_name'] == entity, 'entity_type'].values\n",
    "            assert len(entity_type) > 0, f\"Entity type not found for entity: {entity}\"\n",
    "            G.add_node(entity, entity_type = entity_type[0])\n",
    "                \n",
    "        # Add edges\n",
    "        for _, row in df_input.iterrows():\n",
    "            relationship_type = row['relationship']\n",
    "            assert len(entity_type) > 0, f\"Relationship type not found for entities: {row}\"\n",
    "            G.add_edge(row['entity_1'], row['entity_2'], relationship = relationship_type)\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    \n",
    "    \n",
    "    def join_graphs(G, H):\n",
    "    \n",
    "        \"\"\"\n",
    "        Add nodes and edges from H to G \n",
    "        where entities in H and not in G \n",
    "        have an edge with nodes in G\n",
    "        \"\"\"\n",
    "        \n",
    "        added_edges = 0\n",
    "        joined_graph = G.copy()\n",
    "\n",
    "        for u, v in H.edges():\n",
    "            \n",
    "            if G.has_node(u) or G.has_node(v):\n",
    "                joined_graph.add_edge(u, v, **H[u][v])\n",
    "                added_edges += 1\n",
    "                logger.debug(f\"Relationship added | Entity 1: {u} | Entity 2: {v} | Properties: {H[u][v]}\")\n",
    "\n",
    "        ## Debug information\n",
    "        G_nodes = G.number_of_nodes()\n",
    "        joined_nodes = joined_graph.number_of_nodes()\n",
    "        added_nodes = joined_nodes - G_nodes\n",
    "        \n",
    "        logger.info(f\"Join performed | G Nodes: {G.number_of_nodes()} | Nodes added: {added_nodes} | Edges added: {added_edges} | Joined graph nodes: {joined_graph.number_of_nodes()}\")\n",
    "\n",
    "        return joined_graph\n",
    "    \n",
    "    G = create_graph(G, csv_types)\n",
    "    H = create_graph(csv_input, csv_types)\n",
    "    joined_graph = join_graphs(G, H)\n",
    "    \n",
    "    return joined_graph\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw format main\n",
    "Accepts csv file inputs from already processed XMLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rough_fit_raw(G, csv_input, csv_types):\n",
    "    \n",
    "    # Create input graph\n",
    "    df_input = pd.read_csv(csv_input)\n",
    "    df_types = pd.read_csv(csv_types)\n",
    "    \n",
    "    H = nx.Graph() \n",
    "    \n",
    "    ## Add nodes\n",
    "    entities = set(df_input['entity_1']).union(set(df_input['entity_2']))\n",
    "    \n",
    "    for entity in entities:\n",
    "        entity_type = df_types.loc[df_types['entity_name'] == entity, 'entity_type'].values\n",
    "        assert len(entity_type) > 0, f\"Entity type not found for entity: {entity}\"\n",
    "        H.add_node(entity, entity_type = entity_type[0])\n",
    "            \n",
    "    ## Add edges\n",
    "    for _, row in df_input.iterrows():\n",
    "        relationship_type = row['relationship']\n",
    "        assert len(entity_type) > 0, f\"Relationship type not found for entities: {row}\"\n",
    "        H.add_edge(row['entity_1'], row['entity_2'], relationship = relationship_type)\n",
    "        \n",
    "\n",
    "    # Join G and H\n",
    "    added_edges = 0\n",
    "    joined_graph = G.copy()\n",
    "    \n",
    "    for u, v in H.edges():\n",
    "        \n",
    "        if G.has_node(u) or G.has_node(v):\n",
    "            joined_graph.add_edge(u, v, **H[u][v])\n",
    "            added_edges += 1\n",
    "            logger.debug(f\"Relationship added | Entity 1: {u} | Entity 2: {v} | Properties: {H[u][v]}\")\n",
    "\n",
    "    ## Debug information\n",
    "    G_nodes = G.number_of_nodes()\n",
    "    joined_nodes = joined_graph.number_of_nodes()\n",
    "    added_nodes = joined_nodes - G_nodes\n",
    "    logger.info(f\"Join performed | G Nodes: {G.number_of_nodes()} | Nodes added: {added_nodes} | Edges added: {added_edges} | Joined graph nodes: {joined_graph.number_of_nodes()}\")\n",
    "\n",
    "    return joined_graph\n",
    "    \n",
    "    G = create_graph(G, csv_types)\n",
    "    H = create_graph(csv_input, csv_types)\n",
    "    joined_graph = join_graphs(G, H)\n",
    "    \n",
    "    # return joined_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough Function from XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rough_from_xml(G, xml_data, csv_types):\n",
    "    \n",
    "#     \"\"\"\n",
    "#     Accepts three variables:\n",
    "#     - An existing network graph G\n",
    "#     - A csv file of relationship data\n",
    "#     - A csv file of entity type data\n",
    "#     \"\"\"\n",
    "    \n",
    "    \n",
    "csv_left = \"Extracted Data/relationships_irgc.csv\"\n",
    "csv_right = \"Extracted Data/relationships_mideast.csv\"\n",
    "csv_types = \"Extracted Data/entity_types.csv\"\n",
    "\n",
    "\n",
    "G = create_graph(csv_left, csv_types)\n",
    "\n",
    "def xml_to_json(element):\n",
    "\n",
    "    \"\"\"\n",
    "    Recursively parses XML soup\n",
    "    returning as JSON format \n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(element, str):\n",
    "        return element\n",
    "    \n",
    "    if not element.contents:\n",
    "        return element.string\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for child in element.children:\n",
    "        \n",
    "        if isinstance(child, str):\n",
    "            continue\n",
    "        \n",
    "        if child.name not in result:\n",
    "            result[child.name] = xml_to_json(child)\n",
    "            \n",
    "        else:\n",
    "            if not isinstance(result[child.name], list):\n",
    "                result[child.name] = [result[child.name]]\n",
    "            result[child.name].append(xml_to_json(child))\n",
    "            \n",
    "    ## Capture text nodes without 'text' key\n",
    "    if element.string and element.string.strip():\n",
    "        return element.string.strip()\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_relationships(entity):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a JSON entity, return all available relationship information\n",
    "    \"\"\"\n",
    "    \n",
    "    name_ele = entity[\"names\"][\"name\"]\n",
    "    \n",
    "    ### if name_ele is a dict, only one name entry exists\n",
    "    if type(name_ele) == dict:\n",
    "        \n",
    "        #### Find Latin translation if more than one translation is present\n",
    "        translation_element = name_ele[\"translations\"][\"translation\"]\n",
    "        \n",
    "        if type(translation_element) == dict:\n",
    "                entity_name = translation_element[\"formattedFullName\"]\n",
    "\n",
    "        elif type(translation_element) == list:\n",
    "            for trans in translation_element:\n",
    "                if trans[\"script\"] == \"Latin\":\n",
    "                    entity_name = trans[\"formattedFullName\"]\n",
    "\n",
    "    ### If name element is a list, aliases are present. Collect only primary name\n",
    "    elif type(name_ele) == list:\n",
    "        \n",
    "        #### Find the primary name \n",
    "        for name in name_ele:\n",
    "            if name[\"isPrimary\"] == \"true\":\n",
    "                translation_element = name[\"translations\"][\"translation\"] \n",
    "\n",
    "                ##### Find Latin translation if more than one translation is present\n",
    "                if type(translation_element) == dict:\n",
    "                    entity_name = translation_element[\"formattedFullName\"]\n",
    "                                \n",
    "                elif type(translation_element) == list:\n",
    "                    for trans in translation_element:\n",
    "                        if trans[\"script\"] == \"Latin\":\n",
    "                            entity_name = trans[\"formattedFullName\"]\n",
    "\n",
    "\n",
    "\n",
    "    ## Confirm entity includes relationship information, if not just return entity name and type\n",
    "    if \"relationships\" not in entity.keys(): \n",
    "        return None\n",
    "    if entity[\"relationships\"] == None: \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    ## Collect relationship information\n",
    "    relationships = entity[\"relationships\"][\"relationship\"]\n",
    "    rel_list = []\n",
    "    \n",
    "    ### if relationships is a dict, only one relationship is present\n",
    "    if type(relationships) == dict:\n",
    "        \n",
    "        rel_type = relationships[\"type\"]\n",
    "        rel_entity = relationships[\"relatedEntity\"]\n",
    "        \n",
    "        if rel_entity != None:\n",
    "            rel_list = [entity_name, rel_type, rel_entity]\n",
    "    \n",
    "    ### If relationships is a list, multiple relationships are present \n",
    "    elif type(relationships) == list: \n",
    "        \n",
    "        for rel in relationships:\n",
    "            \n",
    "            rel_type = rel[\"type\"]\n",
    "            rel_entity = rel[\"relatedEntity\"]\n",
    "            \n",
    "            if rel_entity != None:\n",
    "                rel_list.append([entity_name, rel_type, rel_entity]) \n",
    "            \n",
    "    return rel_list\n",
    "\n",
    "def format_name(entity_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    Standardize the format for entity names retrieved from \"formattedFullName\"  \n",
    "    \"\"\"\n",
    "    \n",
    "    # Arrange name based on comma location, if present\n",
    "    if \", \" in entity_name:\n",
    "        name_parts = entity_name.split(\", \")\n",
    "        entity_name = f\"{name_parts[1]} {name_parts[0]}\"\n",
    "    \n",
    "    # Apply title-case formatting\n",
    "    entity_name = entity_name.title()\n",
    "    \n",
    "    # Capitalize any parenthetical text\n",
    "    def capitalize(match):\n",
    "        return match.group(1) + match.group(2).upper() + match.group(3)\n",
    "    \n",
    "    pattern = r'(\\()([^\\)]+)(\\))'\n",
    "    entity_name = re.sub(pattern, capitalize, entity_name)\n",
    "    \n",
    "    return entity_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:31:11 | INFO | loaded\n",
      "21:31:18 | INFO | Entities found: 1520\n",
      "21:31:18 | INFO | Number of edges found: 604\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Entity type not found for entity: Elza Shipping Sa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 92\u001b[0m\n\u001b[1;32m     86\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJoin performed | G Nodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mG\u001b[38;5;241m.\u001b[39mnumber_of_nodes()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Nodes added: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madded_nodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Edges added: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madded_edges\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Joined graph nodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjoined_graph\u001b[38;5;241m.\u001b[39mnumber_of_nodes()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m joined_graph\n\u001b[0;32m---> 92\u001b[0m test_df \u001b[38;5;241m=\u001b[39m test_main(G, xml_file)\n",
      "Cell \u001b[0;32mIn[37], line 61\u001b[0m, in \u001b[0;36mtest_main\u001b[0;34m(G, xml_file)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m entities:\n\u001b[1;32m     60\u001b[0m     entity_type \u001b[38;5;241m=\u001b[39m df_types\u001b[38;5;241m.\u001b[39mloc[df_types[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m entity, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(entity_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntity type not found for entity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mentity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m     H\u001b[38;5;241m.\u001b[39madd_node(entity, entity_type \u001b[38;5;241m=\u001b[39m entity_type[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m### Add edges\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Entity type not found for entity: Elza Shipping Sa"
     ]
    }
   ],
   "source": [
    "xml_file = \"MidEast_sanctions.xml\"\n",
    "\n",
    "def test_main(G, xml_file):\n",
    "    \n",
    "    ## Main Function\n",
    "    ### Load XML Data\n",
    "    try:\n",
    "        with open(xml_file, \"rb\") as file:\n",
    "            xml_data = file.read()\n",
    "            logger.info(f\"loaded\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        logger.info(f\"Input file not found: {xml_data}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.info(f\"An unexpected error occurred: {e}\")\n",
    "        \n",
    "        \n",
    "    ## Parse XML soup, isolate entity data\n",
    "    soup = BeautifulSoup(xml_data, features='xml')\n",
    "    entity_json = xml_to_json(soup)\n",
    "    entity_data = entity_json['sanctionsData'][\"entities\"][\"entity\"]\n",
    "    entity_data = [entity for entity in entity_data if entity[\"generalInfo\"][\"entityType\"] in [\"Individual\", \"Entity\"]]\n",
    "    logger.info(f\"Entities found: {len(entity_data)}\")\n",
    "\n",
    "    ## Extract Edges from JSON\n",
    "    relationships = []\n",
    "    \n",
    "    for entity in entity_data:\n",
    "        \n",
    "        logger.debug(f\"Extracting from entity: {entity[\"generalInfo\"][\"identityId\"]}\")\n",
    "        rel_search = extract_relationships(entity)\n",
    "      \n",
    "        \n",
    "        if rel_search:\n",
    "            if type(rel_search[0]) == str:\n",
    "                relationships.append(rel_search)\n",
    "            \n",
    "            elif type(rel_search == list):\n",
    "                for rel in rel_search:\n",
    "                    relationships.append(rel)\n",
    "            \n",
    "            \n",
    "    ## Convert relationships into a dataframe, apply formatting  \n",
    "    H_df = pd.DataFrame(relationships, columns=['entity_1', 'relationship', 'entity_2'])       \n",
    "    H_df[\"entity_1\"] = H_df[\"entity_1\"].apply(format_name)\n",
    "    H_df[\"entity_2\"] = H_df[\"entity_2\"].apply(format_name)\n",
    "    logger.info(f\"Number of edges found: {H_df.shape[0]}\")\n",
    "\n",
    "\n",
    "    ## Create H graph from input data\n",
    "    df_types = pd.read_csv(csv_types)\n",
    "    \n",
    "    H = nx.Graph() \n",
    "    \n",
    "    ### Add nodes\n",
    "    entities = set(H_df['entity_1']).union(set(H_df['entity_2']))\n",
    "    \n",
    "    for entity in entities:\n",
    "        entity_type = df_types.loc[df_types['entity_name'] == entity, 'entity_type'].values\n",
    "        assert len(entity_type) > 0, f\"Entity type not found for entity: {entity}\"\n",
    "        H.add_node(entity, entity_type = entity_type[0])\n",
    "            \n",
    "    ### Add edges\n",
    "    for _, row in H_df.iterrows():\n",
    "        relationship_type = row['relationship']\n",
    "        assert len(entity_type) > 0, f\"Relationship type not found for entities: {row}\"\n",
    "        H.add_edge(row['entity_1'], row['entity_2'], relationship = relationship_type)\n",
    "        \n",
    "\n",
    "    ## Join G and H\n",
    "    added_edges = 0\n",
    "    joined_graph = G.copy()\n",
    "    \n",
    "    for u, v in H.edges():\n",
    "        \n",
    "        if G.has_node(u) or G.has_node(v):\n",
    "            joined_graph.add_edge(u, v, **H[u][v])\n",
    "            added_edges += 1\n",
    "            logger.debug(f\"Relationship added | Entity 1: {u} | Entity 2: {v} | Properties: {H[u][v]}\")\n",
    "\n",
    "    ## Debug information\n",
    "    G_nodes = G.number_of_nodes()\n",
    "    joined_nodes = joined_graph.number_of_nodes()\n",
    "    added_nodes = joined_nodes - G_nodes\n",
    "    logger.info(f\"Join performed | G Nodes: {G.number_of_nodes()} | Nodes added: {added_nodes} | Edges added: {added_edges} | Joined graph nodes: {joined_graph.number_of_nodes()}\")\n",
    "\n",
    "\n",
    "    return joined_graph\n",
    "\n",
    "    \n",
    "test_df = test_main(G, xml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# relationships = []\n",
    "\n",
    "\n",
    "# entity_types = []\n",
    "\n",
    "# for entity in entity_data:\n",
    "    \n",
    "#     logger.debug(f\"Extracting from entity: {entity[\"generalInfo\"][\"identityId\"]}\")\n",
    "#     rel_search, e_type = extract_relationships(entity)\n",
    "#     e_type = [e_type[0], e_type[1]]\n",
    "#     entity_types.append(e_type)\n",
    "    \n",
    "    \n",
    "#     if rel_search:\n",
    "#         if type(rel_search[0]) == str:\n",
    "#             relationships.append(rel_search)\n",
    "        \n",
    "#         elif type(rel_search == list):\n",
    "#             for rel in rel_search:\n",
    "#                 relationships.append(rel)\n",
    "        \n",
    "        \n",
    "# ## Convert relationships into a dataframe, apply formatting  \n",
    "# rel_df = pd.DataFrame(relationships, columns=['entity_1', 'relationship', 'entity_2'])       \n",
    "# rel_df[\"entity_1\"] = rel_df[\"entity_1\"].apply(format_name)\n",
    "# rel_df[\"entity_2\"] = rel_df[\"entity_2\"].apply(format_name)\n",
    "\n",
    "# type_df = pd.DataFrame(entity_types, columns=[\"entity_name\", \"entity_type\"])\n",
    "# # print(entity_types)\n",
    "# ## Save dataframe as csv\n",
    "# # df.to_csv(args.output_file, index = False)\n",
    "\n",
    "# ## Or return DF if desired \n",
    "# # Seems better for use in main.py \n",
    "# return rel_df, type_df\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     def create_graph(csv_input, csv_types):\n",
    "\n",
    "#         df_input = pd.read_csv(csv_input)\n",
    "#         df_types = pd.read_csv(csv_types)\n",
    "        \n",
    "#         G = nx.Graph() \n",
    "\n",
    "#         # Add nodes with entity_type property\n",
    "#         entities = set(df_input['entity_1']).union(set(df_input['entity_2']))\n",
    "        \n",
    "#         for entity in entities:\n",
    "#             entity_type = df_types.loc[df_types['entity_name'] == entity, 'entity_type'].values\n",
    "#             assert len(entity_type) > 0, f\"Entity type not found for entity: {entity}\"\n",
    "#             G.add_node(entity, entity_type = entity_type[0])\n",
    "                \n",
    "#         # Add edges\n",
    "#         for _, row in df_input.iterrows():\n",
    "#             relationship_type = row['relationship']\n",
    "#             assert len(entity_type) > 0, f\"Relationship type not found for entities: {row}\"\n",
    "#             G.add_edge(row['entity_1'], row['entity_2'], relationship = relationship_type)\n",
    "        \n",
    "#         return G\n",
    "    \n",
    "    \n",
    "    \n",
    "#     def join_graphs(G, H):\n",
    "    \n",
    "#         \"\"\"\n",
    "#         Add nodes and edges from H to G \n",
    "#         where entities in H and not in G \n",
    "#         have an edge with nodes in G\n",
    "#         \"\"\"\n",
    "        \n",
    "#         added_edges = 0\n",
    "#         joined_graph = G.copy()\n",
    "\n",
    "#         for u, v in H.edges():\n",
    "            \n",
    "#             if G.has_node(u) or G.has_node(v):\n",
    "#                 joined_graph.add_edge(u, v, **H[u][v])\n",
    "#                 added_edges += 1\n",
    "#                 logger.debug(f\"Relationship added | Entity 1: {u} | Entity 2: {v} | Properties: {H[u][v]}\")\n",
    "\n",
    "#         ## Debug information\n",
    "#         G_nodes = G.number_of_nodes()\n",
    "#         joined_nodes = joined_graph.number_of_nodes()\n",
    "#         added_nodes = joined_nodes - G_nodes\n",
    "        \n",
    "#         logger.info(f\"Join performed | G Nodes: {G.number_of_nodes()} | Nodes added: {added_nodes} | Edges added: {added_edges} | Joined graph nodes: {joined_graph.number_of_nodes()}\")\n",
    "\n",
    "#         return joined_graph\n",
    "    \n",
    "#     G = create_graph(G, csv_types)\n",
    "#     H = create_graph(csv_input, csv_types)\n",
    "#     joined_graph = join_graphs(G, H)\n",
    "    \n",
    "#     return joined_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_left = \"Extracted Data/relationships_irgc.csv\"\n",
    "# csv_right = \"Extracted Data/relationships_mideast.csv\"\n",
    "# csv_types = \"Extracted Data/entity_types.csv\"\n",
    "# xml_data = \"MidEast_sanctions.xml\"\n",
    "\n",
    "# G = create_graph(csv_left, csv_types)\n",
    "\n",
    "# rough_from_xml(G, xml_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsh-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
